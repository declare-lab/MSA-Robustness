nohup: ignoring input
Start loading the data....
train
Training data loaded!
valid
Validation data loaded!
test
Test data loaded!
Finish loading the data....
Build Graph:
	text_enc.bertmodel.embeddings.word_embeddings.weight True
	text_enc.bertmodel.embeddings.position_embeddings.weight True
	text_enc.bertmodel.embeddings.token_type_embeddings.weight True
	text_enc.bertmodel.embeddings.LayerNorm.weight True
	text_enc.bertmodel.embeddings.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.0.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.0.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.0.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.0.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.0.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.0.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.0.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.0.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.0.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.0.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.0.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.0.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.0.output.dense.weight True
	text_enc.bertmodel.encoder.layer.0.output.dense.bias True
	text_enc.bertmodel.encoder.layer.0.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.0.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.1.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.1.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.1.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.1.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.1.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.1.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.1.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.1.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.1.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.1.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.1.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.1.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.1.output.dense.weight True
	text_enc.bertmodel.encoder.layer.1.output.dense.bias True
	text_enc.bertmodel.encoder.layer.1.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.1.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.2.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.2.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.2.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.2.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.2.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.2.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.2.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.2.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.2.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.2.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.2.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.2.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.2.output.dense.weight True
	text_enc.bertmodel.encoder.layer.2.output.dense.bias True
	text_enc.bertmodel.encoder.layer.2.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.2.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.3.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.3.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.3.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.3.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.3.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.3.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.3.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.3.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.3.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.3.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.3.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.3.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.3.output.dense.weight True
	text_enc.bertmodel.encoder.layer.3.output.dense.bias True
	text_enc.bertmodel.encoder.layer.3.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.3.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.4.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.4.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.4.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.4.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.4.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.4.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.4.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.4.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.4.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.4.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.4.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.4.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.4.output.dense.weight True
	text_enc.bertmodel.encoder.layer.4.output.dense.bias True
	text_enc.bertmodel.encoder.layer.4.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.4.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.5.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.5.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.5.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.5.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.5.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.5.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.5.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.5.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.5.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.5.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.5.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.5.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.5.output.dense.weight True
	text_enc.bertmodel.encoder.layer.5.output.dense.bias True
	text_enc.bertmodel.encoder.layer.5.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.5.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.6.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.6.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.6.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.6.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.6.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.6.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.6.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.6.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.6.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.6.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.6.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.6.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.6.output.dense.weight True
	text_enc.bertmodel.encoder.layer.6.output.dense.bias True
	text_enc.bertmodel.encoder.layer.6.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.6.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.7.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.7.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.7.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.7.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.7.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.7.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.7.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.7.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.7.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.7.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.7.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.7.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.7.output.dense.weight True
	text_enc.bertmodel.encoder.layer.7.output.dense.bias True
	text_enc.bertmodel.encoder.layer.7.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.7.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.8.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.8.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.8.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.8.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.8.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.8.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.8.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.8.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.8.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.8.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.8.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.8.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.8.output.dense.weight True
	text_enc.bertmodel.encoder.layer.8.output.dense.bias True
	text_enc.bertmodel.encoder.layer.8.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.8.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.9.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.9.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.9.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.9.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.9.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.9.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.9.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.9.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.9.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.9.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.9.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.9.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.9.output.dense.weight True
	text_enc.bertmodel.encoder.layer.9.output.dense.bias True
	text_enc.bertmodel.encoder.layer.9.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.9.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.10.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.10.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.10.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.10.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.10.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.10.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.10.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.10.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.10.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.10.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.10.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.10.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.10.output.dense.weight True
	text_enc.bertmodel.encoder.layer.10.output.dense.bias True
	text_enc.bertmodel.encoder.layer.10.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.10.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.11.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.11.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.11.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.11.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.11.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.11.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.11.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.11.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.11.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.11.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.11.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.11.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.11.output.dense.weight True
	text_enc.bertmodel.encoder.layer.11.output.dense.bias True
	text_enc.bertmodel.encoder.layer.11.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.11.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.12.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.12.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.12.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.12.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.12.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.12.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.12.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.12.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.12.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.12.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.12.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.12.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.12.output.dense.weight True
	text_enc.bertmodel.encoder.layer.12.output.dense.bias True
	text_enc.bertmodel.encoder.layer.12.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.12.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.13.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.13.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.13.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.13.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.13.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.13.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.13.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.13.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.13.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.13.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.13.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.13.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.13.output.dense.weight True
	text_enc.bertmodel.encoder.layer.13.output.dense.bias True
	text_enc.bertmodel.encoder.layer.13.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.13.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.14.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.14.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.14.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.14.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.14.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.14.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.14.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.14.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.14.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.14.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.14.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.14.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.14.output.dense.weight True
	text_enc.bertmodel.encoder.layer.14.output.dense.bias True
	text_enc.bertmodel.encoder.layer.14.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.14.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.15.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.15.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.15.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.15.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.15.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.15.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.15.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.15.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.15.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.15.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.15.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.15.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.15.output.dense.weight True
	text_enc.bertmodel.encoder.layer.15.output.dense.bias True
	text_enc.bertmodel.encoder.layer.15.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.15.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.16.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.16.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.16.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.16.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.16.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.16.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.16.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.16.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.16.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.16.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.16.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.16.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.16.output.dense.weight True
	text_enc.bertmodel.encoder.layer.16.output.dense.bias True
	text_enc.bertmodel.encoder.layer.16.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.16.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.17.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.17.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.17.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.17.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.17.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.17.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.17.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.17.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.17.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.17.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.17.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.17.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.17.output.dense.weight True
	text_enc.bertmodel.encoder.layer.17.output.dense.bias True
	text_enc.bertmodel.encoder.layer.17.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.17.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.18.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.18.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.18.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.18.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.18.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.18.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.18.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.18.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.18.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.18.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.18.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.18.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.18.output.dense.weight True
	text_enc.bertmodel.encoder.layer.18.output.dense.bias True
	text_enc.bertmodel.encoder.layer.18.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.18.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.19.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.19.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.19.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.19.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.19.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.19.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.19.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.19.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.19.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.19.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.19.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.19.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.19.output.dense.weight True
	text_enc.bertmodel.encoder.layer.19.output.dense.bias True
	text_enc.bertmodel.encoder.layer.19.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.19.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.20.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.20.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.20.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.20.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.20.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.20.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.20.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.20.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.20.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.20.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.20.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.20.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.20.output.dense.weight True
	text_enc.bertmodel.encoder.layer.20.output.dense.bias True
	text_enc.bertmodel.encoder.layer.20.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.20.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.21.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.21.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.21.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.21.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.21.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.21.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.21.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.21.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.21.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.21.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.21.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.21.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.21.output.dense.weight True
	text_enc.bertmodel.encoder.layer.21.output.dense.bias True
	text_enc.bertmodel.encoder.layer.21.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.21.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.22.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.22.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.22.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.22.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.22.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.22.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.22.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.22.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.22.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.22.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.22.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.22.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.22.output.dense.weight True
	text_enc.bertmodel.encoder.layer.22.output.dense.bias True
	text_enc.bertmodel.encoder.layer.22.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.22.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.23.attention.self.query.weight True
	text_enc.bertmodel.encoder.layer.23.attention.self.query.bias True
	text_enc.bertmodel.encoder.layer.23.attention.self.key.weight True
	text_enc.bertmodel.encoder.layer.23.attention.self.key.bias True
	text_enc.bertmodel.encoder.layer.23.attention.self.value.weight True
	text_enc.bertmodel.encoder.layer.23.attention.self.value.bias True
	text_enc.bertmodel.encoder.layer.23.attention.output.dense.weight True
	text_enc.bertmodel.encoder.layer.23.attention.output.dense.bias True
	text_enc.bertmodel.encoder.layer.23.attention.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.23.attention.output.LayerNorm.bias True
	text_enc.bertmodel.encoder.layer.23.intermediate.dense.weight True
	text_enc.bertmodel.encoder.layer.23.intermediate.dense.bias True
	text_enc.bertmodel.encoder.layer.23.output.dense.weight True
	text_enc.bertmodel.encoder.layer.23.output.dense.bias True
	text_enc.bertmodel.encoder.layer.23.output.LayerNorm.weight True
	text_enc.bertmodel.encoder.layer.23.output.LayerNorm.bias True
	text_enc.bertmodel.pooler.dense.weight True
	text_enc.bertmodel.pooler.dense.bias True
	visual_enc.rnn.weight_ih_l0 True
	visual_enc.rnn.weight_hh_l0 True
	visual_enc.rnn.bias_ih_l0 True
	visual_enc.rnn.bias_hh_l0 True
	visual_enc.linear_1.weight True
	visual_enc.linear_1.bias True
	acoustic_enc.rnn.weight_ih_l0 True
	acoustic_enc.rnn.weight_hh_l0 True
	acoustic_enc.rnn.bias_ih_l0 True
	acoustic_enc.rnn.bias_hh_l0 True
	acoustic_enc.linear_1.weight True
	acoustic_enc.linear_1.bias True
	mi_tv.mlp_mu.0.weight True
	mi_tv.mlp_mu.0.bias True
	mi_tv.mlp_mu.2.weight True
	mi_tv.mlp_mu.2.bias True
	mi_tv.mlp_logvar.0.weight True
	mi_tv.mlp_logvar.0.bias True
	mi_tv.mlp_logvar.2.weight True
	mi_tv.mlp_logvar.2.bias True
	mi_tv.entropy_prj.0.weight True
	mi_tv.entropy_prj.0.bias True
	mi_ta.mlp_mu.0.weight True
	mi_ta.mlp_mu.0.bias True
	mi_ta.mlp_mu.2.weight True
	mi_ta.mlp_mu.2.bias True
	mi_ta.mlp_logvar.0.weight True
	mi_ta.mlp_logvar.0.bias True
	mi_ta.mlp_logvar.2.weight True
	mi_ta.mlp_logvar.2.bias True
	mi_ta.entropy_prj.0.weight True
	mi_ta.entropy_prj.0.bias True
	cpc_zt.net.weight True
	cpc_zt.net.bias True
	cpc_zv.net.weight True
	cpc_zv.net.bias True
	cpc_za.net.weight True
	cpc_za.net.bias True
	fusion_prj.linear_1.weight True
	fusion_prj.linear_1.bias True
	fusion_prj.linear_2.weight True
	fusion_prj.linear_2.bias True
	fusion_prj.linear_3.weight True
	fusion_prj.linear_3.bias True
Epoch  1 | Batch 100/255 | Time/Batch(ms) 788.59 | Train Loss (Neg-lld) 4.1241 | NCE 12.507 | BA 4.1241
Epoch  1 | Batch 100/255 | Time/Batch(ms) 911.37 | Train Loss (TASK+BA+CPC) 2.6803 | NCE 12.380 | BA 13.8571
Epoch  1 | Batch 200/255 | Time/Batch(ms) 898.76 | Train Loss (TASK+BA+CPC) 2.3351 | NCE 12.060 | BA 10.1859
--------------------------------------------------
Epoch  1 | Time 355.7185 sec | Valid Loss 0.5572 | Test Loss 0.5791
--------------------------------------------------
mae:  0.57913965
corr:  0.7330123269751859
mult_acc:  0.5129856192315948
Classification Report (pos/neg) :
              precision    recall  f1-score   support

       False    0.84275   0.71852   0.77569      1350
        True    0.84696   0.92075   0.88232      2284

    accuracy                        0.84562      3634
   macro avg    0.84485   0.81964   0.82900      3634
weighted avg    0.84539   0.84562   0.84271      3634

Accuracy (pos/neg)  0.8456246560264171
Classification Report (non-neg/neg) :
              precision    recall  f1-score   support

       False    0.71481   0.71852   0.71666      1350
        True    0.88492   0.88305   0.88398      3309

    accuracy                        0.83537      4659
   macro avg    0.79987   0.80078   0.80032      4659
weighted avg    0.83563   0.83537   0.83550      4659

Accuracy (non-neg/neg)  0.8353723975101953
Saved model at pre_trained_models/MM.pt!
-------------------------save_dir
pre_trained_models/mosei/best_0%L=0/
Epoch  2 | Batch 100/255 | Time/Batch(ms) 801.10 | Train Loss (Neg-lld) 1.4801 | NCE 11.563 | BA 1.4801
Epoch  2 | Batch 100/255 | Time/Batch(ms) 903.92 | Train Loss (TASK+BA+CPC) 2.1715 | NCE 11.329 | BA 10.0828
Epoch  2 | Batch 200/255 | Time/Batch(ms) 904.07 | Train Loss (TASK+BA+CPC) 2.1018 | NCE 10.820 | BA 9.5981
--------------------------------------------------
Epoch  2 | Time 357.3277 sec | Valid Loss 0.5352 | Test Loss 0.5477
--------------------------------------------------
mae:  0.5476571
corr:  0.7493531545156853
mult_acc:  0.536381197681906
Classification Report (pos/neg) :
              precision    recall  f1-score   support

       False    0.71973   0.85407   0.78117      1350
        True    0.90305   0.80342   0.85032      2284

    accuracy                        0.82223      3634
   macro avg    0.81139   0.82874   0.81574      3634
weighted avg    0.83495   0.82223   0.82463      3634

Accuracy (pos/neg)  0.8222344523940561
Classification Report (non-neg/neg) :
              precision    recall  f1-score   support

       False    0.54055   0.85407   0.66207      1350
        True    0.92201   0.70384   0.79829      3309

    accuracy                        0.74737      4659
   macro avg    0.73128   0.77896   0.73018      4659
weighted avg    0.81148   0.74737   0.75882      4659

Accuracy (non-neg/neg)  0.7473706804035201
Saved model at pre_trained_models/MM.pt!
-------------------------save_dir
pre_trained_models/mosei/best_0%L=0/
Epoch  3 | Batch 100/255 | Time/Batch(ms) 799.95 | Train Loss (Neg-lld) 1.7001 | NCE 10.498 | BA 1.7001
Epoch  3 | Batch 100/255 | Time/Batch(ms) 910.94 | Train Loss (TASK+BA+CPC) 2.0958 | NCE 10.409 | BA 11.6961
Epoch  3 | Batch 200/255 | Time/Batch(ms) 896.80 | Train Loss (TASK+BA+CPC) 2.0767 | NCE 10.308 | BA 11.5296
--------------------------------------------------
Epoch  3 | Time 356.8357 sec | Valid Loss 0.5498 | Test Loss 0.5731
--------------------------------------------------
Epoch  4 | Batch 100/255 | Time/Batch(ms) 800.01 | Train Loss (Neg-lld) 1.8097 | NCE 10.238 | BA 1.8097
Epoch  4 | Batch 100/255 | Time/Batch(ms) 904.88 | Train Loss (TASK+BA+CPC) 2.1481 | NCE 10.245 | BA 14.2077
Epoch  4 | Batch 200/255 | Time/Batch(ms) 900.64 | Train Loss (TASK+BA+CPC) 2.1390 | NCE 10.186 | BA 14.1118
--------------------------------------------------
Epoch  4 | Time 356.3956 sec | Valid Loss 0.6481 | Test Loss 0.6585
--------------------------------------------------
Epoch  5 | Batch 100/255 | Time/Batch(ms) 801.94 | Train Loss (Neg-lld) 1.8952 | NCE 10.179 | BA 1.8952
Epoch  5 | Batch 100/255 | Time/Batch(ms) 910.34 | Train Loss (TASK+BA+CPC) 2.2532 | NCE 10.171 | BA 17.2218
Epoch  5 | Batch 200/255 | Time/Batch(ms) 900.04 | Train Loss (TASK+BA+CPC) 2.2729 | NCE 10.176 | BA 17.2399
--------------------------------------------------
Epoch  5 | Time 357.0349 sec | Valid Loss 0.5366 | Test Loss 0.5594
--------------------------------------------------
Epoch  6 | Batch 100/255 | Time/Batch(ms) 802.29 | Train Loss (Neg-lld) 1.9609 | NCE 10.140 | BA 1.9609
Epoch  6 | Batch 100/255 | Time/Batch(ms) 903.42 | Train Loss (TASK+BA+CPC) 2.4053 | NCE 10.140 | BA 20.7912
Epoch  6 | Batch 200/255 | Time/Batch(ms) 901.10 | Train Loss (TASK+BA+CPC) 2.4074 | NCE 10.124 | BA 20.8570
--------------------------------------------------
Epoch  6 | Time 356.8078 sec | Valid Loss 0.5385 | Test Loss 0.5610
--------------------------------------------------
Epoch  7 | Batch 100/255 | Time/Batch(ms) 799.12 | Train Loss (Neg-lld) 2.0254 | NCE 10.123 | BA 2.0254
Epoch  7 | Batch 100/255 | Time/Batch(ms) 907.61 | Train Loss (TASK+BA+CPC) 2.5634 | NCE 10.117 | BA 24.7360
Epoch  7 | Batch 200/255 | Time/Batch(ms) 897.61 | Train Loss (TASK+BA+CPC) 2.5939 | NCE 10.111 | BA 24.8790
--------------------------------------------------
Epoch  7 | Time 356.2121 sec | Valid Loss 0.5770 | Test Loss 0.6001
--------------------------------------------------
Epoch  8 | Batch 100/255 | Time/Batch(ms) 799.60 | Train Loss (Neg-lld) 1.9640 | NCE 10.113 | BA 1.9640
Epoch  8 | Batch 100/255 | Time/Batch(ms) 909.04 | Train Loss (TASK+BA+CPC) 2.7616 | NCE 10.102 | BA 29.1001
Epoch  8 | Batch 200/255 | Time/Batch(ms) 906.14 | Train Loss (TASK+BA+CPC) 2.7878 | NCE 10.093 | BA 29.3051
--------------------------------------------------
Epoch  8 | Time 357.4912 sec | Valid Loss 0.5949 | Test Loss 0.6225
--------------------------------------------------
Epoch  9 | Batch 100/255 | Time/Batch(ms) 800.72 | Train Loss (Neg-lld) 2.0031 | NCE 10.084 | BA 2.0031
Epoch  9 | Batch 100/255 | Time/Batch(ms) 903.01 | Train Loss (TASK+BA+CPC) 2.9713 | NCE 10.088 | BA 33.8753
Epoch  9 | Batch 200/255 | Time/Batch(ms) 898.30 | Train Loss (TASK+BA+CPC) 2.9906 | NCE 10.080 | BA 34.1301
--------------------------------------------------
Epoch  9 | Time 355.8663 sec | Valid Loss 0.5629 | Test Loss 0.5791
--------------------------------------------------
Epoch 10 | Batch 100/255 | Time/Batch(ms) 800.09 | Train Loss (Neg-lld) 2.0128 | NCE 10.110 | BA 2.0128
Epoch 10 | Batch 100/255 | Time/Batch(ms) 897.91 | Train Loss (TASK+BA+CPC) 3.1977 | NCE 10.069 | BA 39.1920
Epoch 10 | Batch 200/255 | Time/Batch(ms) 904.76 | Train Loss (TASK+BA+CPC) 3.2213 | NCE 10.065 | BA 39.4647
--------------------------------------------------
Epoch 10 | Time 356.2750 sec | Valid Loss 0.5492 | Test Loss 0.5653
--------------------------------------------------
Epoch 11 | Batch 100/255 | Time/Batch(ms) 800.97 | Train Loss (Neg-lld) 1.9355 | NCE 10.080 | BA 1.9355
Epoch 11 | Batch 100/255 | Time/Batch(ms) 906.00 | Train Loss (TASK+BA+CPC) 3.4777 | NCE 10.075 | BA 45.1022
Epoch 11 | Batch 200/255 | Time/Batch(ms) 896.58 | Train Loss (TASK+BA+CPC) 3.4939 | NCE 10.067 | BA 45.3598
--------------------------------------------------
Epoch 11 | Time 356.1680 sec | Valid Loss 0.5912 | Test Loss 0.6038
--------------------------------------------------
Epoch 12 | Batch 100/255 | Time/Batch(ms) 798.10 | Train Loss (Neg-lld) 1.9099 | NCE 10.088 | BA 1.9099
Epoch 12 | Batch 100/255 | Time/Batch(ms) 905.84 | Train Loss (TASK+BA+CPC) 3.8640 | NCE 10.156 | BA 51.5877
Epoch 12 | Batch 200/255 | Time/Batch(ms) 901.59 | Train Loss (TASK+BA+CPC) 3.8397 | NCE 10.101 | BA 51.9255
--------------------------------------------------
Epoch 12 | Time 355.8947 sec | Valid Loss 0.6071 | Test Loss 0.6164
--------------------------------------------------
Best epoch: 2
mae:  0.5476571
corr:  0.7493531545156853
mult_acc:  0.536381197681906
Classification Report (pos/neg) :
              precision    recall  f1-score   support

       False    0.71973   0.85407   0.78117      1350
        True    0.90305   0.80342   0.85032      2284

    accuracy                        0.82223      3634
   macro avg    0.81139   0.82874   0.81574      3634
weighted avg    0.83495   0.82223   0.82463      3634

Accuracy (pos/neg)  0.8222344523940561
Classification Report (non-neg/neg) :
              precision    recall  f1-score   support

       False    0.54055   0.85407   0.66207      1350
        True    0.92201   0.70384   0.79829      3309

    accuracy                        0.74737      4659
   macro avg    0.73128   0.77896   0.73018      4659
weighted avg    0.81148   0.74737   0.75882      4659

Accuracy (non-neg/neg)  0.7473706804035201
/home/yingting/Multimodal-Infomax/src/solver.py:197: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with autograd.detect_anomaly():
/home/yingting/Multimodal-Infomax/src/solver.py:184: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with autograd.detect_anomaly():
